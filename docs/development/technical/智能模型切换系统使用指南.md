# 智能模型切换系统使用指南 🚀

## 📋 功能概述

VideoGenius的智能模型切换系统是一个企业级的AI模型管理解决方案，支持**13种**主流AI模型的智能路由、负载均衡和故障转移。

### 🎯 核心特性

- **🤖 多模型支持**: 集成13种主流AI模型（DeepSeek、Claude、GPT-4、文心一言等）
- **🧠 智能路由**: 基于性能、成本、可用性的智能模型选择
- **⚖️ 负载均衡**: 6种负载均衡策略，优化资源利用
- **🔄 故障转移**: 自动检测故障并切换到备用模型
- **📊 实时监控**: 全面的性能指标和健康状态监控
- **🎛️ 灵活配置**: 支持权重调整、备用链设置等高级配置

### 🌟 支持的AI模型

| 模型 | 提供商 | 国内访问 | 免费额度 | 推荐指数 |
|---------|--------|----------|----------|----------|
| DeepSeek | DeepSeek | ✅ | ✅ | ⭐⭐⭐⭐⭐ |
| Claude | Anthropic | ❌ | ❌ | ⭐⭐⭐⭐ |
| Ernie | 百度 | ✅ | ✅ | ⭐⭐⭐⭐ |
| Moonshot | 月之暗面 | ✅ | ✅ | ⭐⭐⭐⭐ |
| OpenAI | OpenAI | ❌ | ❌ | ⭐⭐⭐ |
| Ollama | 本地 | ✅ | ✅ | ⭐⭐⭐ |
| Azure | Microsoft | ❌ | ❌ | ⭐⭐⭐ |
| Gemini | Google | ❌ | ✅ | ⭐⭐⭐ |
| Qwen | 阿里云 | ✅ | ✅ | ⭐⭐⭐ |
| OneAPI | 统一代理 | ✅ | ✅ | ⭐⭐⭐ |
| G4F | 免费代理 | ✅ | ✅ | ⭐⭐ |
| Cloudflare | Cloudflare | ❌ | ✅ | ⭐⭐ |
| Pollinations | Pollinations | ✅ | ✅ | ⭐⭐ |

---

## 🔧 核心技术架构

### 🔍 健康检查系统
- **实时监控**: 每5分钟自动检查所有配置模型的健康状态
- **性能指标**: 监控响应时间、成功率、连续失败次数等关键指标
- **状态分类**: 健康(Healthy)、降级(Degraded)、不健康(Unhealthy)、未知(Unknown)
- **成本估算**: 实时计算每个模型的使用成本

### 🧠 智能路由算法
**综合评分算法**：
- 基础权重 (30%)：模型的基础优先级
- 健康状态 (25%)：当前模型的健康程度
- 性能指标 (20%)：响应时间和处理速度
- 可靠性 (15%)：成功率和稳定性
- 成本因素 (10%)：使用成本考量

**高级功能**：
- 动态权重调整：支持运行时调整模型权重
- 备用链机制：预设的故障转移顺序
- 地理位置优化：根据用户位置选择最近的模型服务

### 🔄 故障转移机制
- **自动检测**: 实时检测模型故障和异常
- **快速切换**: 1秒内完成故障模型切换
- **多重重试**: 最多3次重试，每次选择不同的最佳模型
- **自动恢复**: 检测到模型恢复后自动重新启用

### ⚖️ 负载均衡策略
支持6种负载均衡策略：

1. **轮询 (Round Robin)**: 简单的循环选择
2. **加权轮询 (Weighted Round Robin)**: 基于权重的随机选择
3. **最少连接 (Least Connections)**: 选择当前活跃请求最少的模型
4. **响应时间优先 (Response Time)**: 选择响应最快的模型
5. **随机 (Random)**: 随机选择健康模型
6. **智能选择 (Intelligent)**: 基于综合评分的最优选择

---

## 快速开始

### 1. 基础使用

```python
from app.services.llm_enhanced import EnhancedLLMService

# 创建服务实例
service = EnhancedLLMService()

# 配置服务
service.configure(
    intelligent_routing=True,      # 启用智能路由
    load_balancing=True,          # 启用负载均衡
    failover=True,                # 启用故障转移
    load_balance_strategy=LoadBalanceStrategy.INTELLIGENT
)

# 生成视频脚本
script = await service.generate_script_async(
    video_subject="人工智能的发展",
    language="zh-CN",
    paragraph_number=2
)

# 生成关键词
terms = await service.generate_terms_async(
    video_subject="人工智能",
    video_script=script,
    amount=5
)
```

### 2. 同步接口使用

```python
# 兼容原有API的同步接口
script = service.generate_script("人工智能的发展", language="zh-CN")
terms = service.generate_terms("人工智能", script, 5)
```

### 3. 配置管理

```python
# 动态调整模型权重
service.router.update_model_weights({
    "deepseek": 1.2,  # 提高DeepSeek权重
    "claude": 0.8     # 降低Claude权重
})

# 设置备用链
service.router.set_fallback_chain([
    "deepseek", "ernie", "claude", "openai"
])

# 强制健康检查
service.force_health_check("deepseek")  # 检查单个模型
service.force_health_check()            # 检查所有模型
```

## 监控和统计

### 1. 服务统计

```python
stats = service.get_service_stats()
print(f"总请求数: {stats['total_requests']}")
print(f"成功率: {stats['success_rate']:.2%}")
print(f"平均响应时间: {stats['avg_response_time']:.2f}s")
print(f"运行时间: {stats['uptime_formatted']}")
```

### 2. 模型健康状态

```python
health = service.get_model_health_status()
for model, metrics in health.items():
    print(f"{model}: {metrics.status.value}")
    print(f"  响应时间: {metrics.response_time:.2f}s")
    print(f"  成功率: {metrics.success_rate:.2%}")
```

### 3. 负载均衡统计

```python
load_stats = service.get_load_balancer_stats()
for model, stats in load_stats.items():
    print(f"{model}:")
    print(f"  总请求: {stats['total_requests']}")
    print(f"  活跃请求: {stats['active_requests']}")
    print(f"  平均响应时间: {stats['avg_response_time']}s")
```

## 配置文件设置

在 `config.toml` 中添加模型权重配置：

```toml
[app.model_weights]
deepseek = 1.0
claude = 0.9
ernie = 0.95
moonshot = 0.85
openai = 0.8
ollama = 0.7
azure = 0.8
gemini = 0.75
qwen = 0.85
```

## 性能优化建议

### 1. 模型选择策略
- **国内用户**：优先使用 DeepSeek、Ernie、Moonshot
- **海外用户**：优先使用 Claude、OpenAI、Gemini
- **本地部署**：考虑使用 Ollama

### 2. 负载均衡策略选择
- **高并发场景**：使用 `LEAST_CONNECTIONS` 或 `INTELLIGENT`
- **稳定性优先**：使用 `RESPONSE_TIME` 或 `WEIGHTED_ROUND_ROBIN`
- **简单场景**：使用 `ROUND_ROBIN`

### 3. 健康检查优化
- 调整检查间隔：默认5分钟，可根据需要调整
- 设置合理的超时时间：避免长时间等待
- 监控关键指标：重点关注成功率和响应时间

## 故障排除

### 1. 常见问题

**Q: 所有模型都显示不健康怎么办？**
A: 检查网络连接和API Key配置，确保至少有一个模型配置正确。

**Q: 响应时间很慢怎么办？**
A: 检查网络状况，考虑使用国内模型或调整负载均衡策略。

**Q: 故障转移不生效怎么办？**
A: 确认 `failover=True` 且至少配置了2个以上的模型。

### 2. 调试模式

```python
# 启用详细日志
import logging
logging.getLogger().setLevel(logging.DEBUG)

# 查看详细的模型选择过程
service.router.select_best_model("script")  # 会输出详细的评分过程
```

### 3. 重置统计

```python
# 重置所有统计信息
service.reset_stats()
```

## 最佳实践

### 1. 生产环境配置
```python
service.configure(
    intelligent_routing=True,
    load_balancing=True,
    failover=True,
    load_balance_strategy=LoadBalanceStrategy.INTELLIGENT
)
```

### 2. 开发环境配置
```python
service.configure(
    intelligent_routing=False,  # 关闭智能路由，使用固定模型
    load_balancing=False,
    failover=False
)
```

### 3. 监控告警
- 定期检查服务统计信息
- 监控模型健康状态变化
- 设置成功率阈值告警

## 技术架构

```
┌─────────────────────────────────────────────────────────────┐
│                    EnhancedLLMService                       │
├─────────────────────────────────────────────────────────────┤
│  ┌─────────────────┐  ┌─────────────────┐  ┌─────────────────┐ │
│  │  Health Checker │  │ Intelligent     │  │ Load Balancer   │ │
│  │                 │  │ Router          │  │                 │ │
│  │ • 健康监控      │  │ • 智能选择      │  │ • 负载分配      │ │
│  │ • 性能统计      │  │ • 评分算法      │  │ • 策略管理      │ │
│  │ • 状态管理      │  │ • 权重调整      │  │ • 并发控制      │ │
│  └─────────────────┘  └─────────────────┘  └─────────────────┘ │
├─────────────────────────────────────────────────────────────┤
│                    Failover Manager                         │
│  • 故障检测  • 自动切换  • 重试机制  • 恢复检测            │
├─────────────────────────────────────────────────────────────┤
│                      AI Models                              │
│  DeepSeek │ Claude │ Ernie │ Moonshot │ OpenAI │ Ollama...  │
└─────────────────────────────────────────────────────────────┘
```

## 更新日志

### v2.0.0 (2025-05-28)
- ✅ 新增智能模型切换系统
- ✅ 支持9种AI模型的健康检查
- ✅ 实现智能路由和故障转移
- ✅ 添加6种负载均衡策略
- ✅ 完善性能监控和统计
- ✅ 提供完整的API兼容性

---

如有问题或建议，请提交 Issue 或联系开发团队。 